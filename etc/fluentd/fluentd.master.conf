# 主日志收集服务 172.31.0.52 默认配置文件 备用服务 backup 172.31.0.112
# 输入
<source>
  @type forward
  bind 0.0.0.0
  port 24224
</source>

# 输出es
<match data_center_log.**>
  #表示写入es
  @type elasticsearch
  #是否开启logstash日志格式化
  logstash_format true
  #flush时间间隔
  flush_interval 20s
  #es连接ip http://172.31.0.47:9200/
  host 172.31.0.47
  #es连接端口号
  port 9200
  user elastic
  password 0BJltywb$#@987
  #在es创建得index名称   这里使用tag-时间
  index_name ${tag}-%Y.%m
  logstash_prefix ${tag}
  include_tag_key true
  <buffer tag, time>
      #默认单位s   s/m/h   多久会产生一个chunk
      timekey 1h
      #默认单位s   s/m/h   是指当前chunk 结束了以后，延迟多长时间，才把该chunk   flush到文件里
      timekey_wait 10
  </buffer>
</match>
# 输出到本地文件
<match out_local.**>
  @type file
  path /var/log/fluentd/aggregator/${tag}
  # compress gzip
  <buffer tag,time>
     @type file
     path /var/log/fluentd/buffer/${tag}
     flush_mode interval
     flush_interval 80s
     timekey 1d
     timekey_use_utc true
     timekey_wait 10m
     total_limit_size 20G
     chunk_limit_size 45M
  </buffer>
  <secondary>
      @type file
      path /var/log/fluentd/aggregator/failed_records
  </secondary>
</match>