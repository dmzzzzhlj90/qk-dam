# 主日志收集服务 172.31.0.52 默认配置文件 备用服务 backup 172.31.0.112
# 输入
<source>
  @type forward
  bind 0.0.0.0
  port 24224
  @label @LOGAGG
</source>
# HTTP输入源
<source>
  @type http
  @id http_input
  port 8683
  bind 0.0.0.0
  body_size_limit 48m
  keepalive_timeout 60s
  @label @LOGAGG
</source>

<label @LOGAGG>
# 输出es
<match data_center_log.**>
  #表示写入es
  @type elasticsearch
  #是否开启logstash日志格式化
  logstash_format true
  #flush时间间隔
  flush_interval 20s
  #es连接ip http://172.31.0.47:9200/
  host 172.31.0.47
  #es连接端口号
  port 9200
  user elastic
  password 0BJltywb$#@987
  #在es创建得index名称   这里使用tag-时间
  index_name ${tag}-%Y.%m.%d
  logstash_prefix ${tag}
  include_tag_key true
  <buffer tag, time>
      #默认单位s   s/m/h   多久会产生一个chunk
      timekey 1h
      #默认单位s   s/m/h   是指当前chunk 结束了以后，延迟多长时间，才把该chunk   flush到文件里
      timekey_wait 10
  </buffer>
</match>
# 输出到本地文件
<match out_local.**>
 @type copy
 <store>
     @type file
     path /var/log/fluentd/aggregator/${tag}
     compress gzip
     <buffer tag,time>
        @type file
        path /var/log/fluentd/buffer/${tag}
        flush_mode interval
        flush_interval 80s
        timekey 1d
        timekey_use_utc true
        timekey_wait 10m
        total_limit_size 20G
        chunk_limit_size 5M
     </buffer>
 </store>

  <secondary>
      @type file
      path /var/log/fluentd/aggregator/failed_records
  </secondary>
</match>
</label>